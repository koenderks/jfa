<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Algorithm auditing: Get started • jfa</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Algorithm auditing: Get started">
<meta property="og:description" content="jfa">
<meta property="og:image" content="https://koenderks.github.io/jfa/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">jfa</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.7.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/jfa.html">Get started</a>
</li>
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/koenderks/jfa" class="external-link">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/koenderks/jfa/discussions" class="external-link">
    <span class="fa fa-users"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Algorithm auditing: Get started</h1>
                        <h4 data-toc-skip class="author">Koen Derks</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/koenderks/jfa/blob/HEAD/vignettes/articles/algorithm-auditing.Rmd" class="external-link"><code>vignettes/articles/algorithm-auditing.Rmd</code></a></small>
      <div class="hidden name"><code>algorithm-auditing.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Welcome to the ‘Algorithm auditing’ vignette of the
<strong>jfa</strong> package. This page provides a guide to the
functions in the package that are designed to facilitate the audit of
algorithms and predictive models. In particular, these functions
implement techniques for calculating and testing fairness metrics. The
package allows users to specify a prior probability distribution to
conduct Bayesian algorithm auditing using these functions.</p>
</div>
<div class="section level2">
<h2 id="functions-and-intended-usage">Functions and intended usage<a class="anchor" aria-label="anchor" href="#functions-and-intended-usage"></a>
</h2>
<p>Below you can find an explanation of the available algorithm auditing
functions in <strong>jfa</strong>.</p>
<ul>
<li><a href="#testing-algorithmic-fairness"><code>model_fairness()</code></a></li>
</ul>
<div class="section level3">
<h3 id="testing-algorithmic-fairness">Testing algorithmic fairness<a class="anchor" aria-label="anchor" href="#testing-algorithmic-fairness"></a>
</h3>
<p>The <code><a href="../reference/model_fairness.html">model_fairness()</a></code> function is designed to evaluate
fairness in algorithmic decision-making systems. It does this by
computing and testing the equality of various model-agnostic fairness
metrics between protected classes, based on a set of true labels and the
predictions of an algorithm. The ratio of these metrics between an
unprivileged protected class and a privileged protected class is
referred to as parity, which quantifies relative fairness in the
algorithm’s predictions. Available parity metrics include predictive
rate parity, proportional parity, accuracy parity, false negative rate
parity, false positive rate parity, true positive rate parity, negative
predicted value parity, specificity parity, and demographic parity <span class="citation">(Friedler et al., 2019; Pessach &amp; Shmueli,
2022)</span>. The function returns an object that can be used with the
associated <code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> and <code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> methods.</p>
<p>For additional details about this function, please refer to the <a href="https://koenderks.github.io/jfa/reference/model_fairness.html">function
documentation</a> on the package website.</p>
<p><em>Example usage:</em></p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compare predictive rate parity</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/model_fairness.html">model_fairness</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">compas</span>,</span>
<span>  protected <span class="op">=</span> <span class="st">"Ethnicity"</span>,</span>
<span>  target <span class="op">=</span> <span class="st">"TwoYrRecidivism"</span>,</span>
<span>  predictions <span class="op">=</span> <span class="st">"Predicted"</span>,</span>
<span>  privileged <span class="op">=</span> <span class="st">"Caucasian"</span>,</span>
<span>  positive <span class="op">=</span> <span class="st">"yes"</span>,</span>
<span>  metric <span class="op">=</span> <span class="st">"prp"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">##  Classical Algorithmic Fairness Test Summary</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Options:</span></span>
<span><span class="co">##   Confidence level:    0.95 </span></span>
<span><span class="co">##   Fairness metric:     Predictive rate parity (Equalized odds)</span></span>
<span><span class="co">##   Model type:          Binary classification</span></span>
<span><span class="co">##   Privileged group:    Caucasian</span></span>
<span><span class="co">##   Positive class:      yes </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Data:</span></span>
<span><span class="co">##   Sample size:         6172 </span></span>
<span><span class="co">##   Unprivileged groups: 5 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Results:</span></span>
<span><span class="co">##   X-squared:           18.799 </span></span>
<span><span class="co">##   Degrees of freedom:  5 </span></span>
<span><span class="co">##   p-value:             0.0020951 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Comparisons to privileged (P) group:</span></span>
<span><span class="co">##                                     Precision                    Parity</span></span>
<span><span class="co">##   Caucasian (P)    0.57738 [0.53902, 0.61506]                         -</span></span>
<span><span class="co">##   African_American  0.66525 [0.6434, 0.68658]   1.1522 [1.1143, 1.1891]</span></span>
<span><span class="co">##   Asian               0.5 [0.067586, 0.93241] 0.86598 [0.11706, 1.6149]</span></span>
<span><span class="co">##   Hispanic          0.5906 [0.50715, 0.67038]  1.0229 [0.87836, 1.1611]</span></span>
<span><span class="co">##   Native_American      0.6 [0.14663, 0.94726]  1.0392 [0.25396, 1.6406]</span></span>
<span><span class="co">##   Other            0.61176 [0.49988, 0.71562]  1.0596 [0.86578, 1.2394]</span></span>
<span><span class="co">##                                    Odds ratio    p-value</span></span>
<span><span class="co">##   Caucasian (P)                             -          -</span></span>
<span><span class="co">##   African_American    1.4543 [1.2087, 1.7491] 5.4523e-05</span></span>
<span><span class="co">##   Asian            0.73231 [0.052801, 10.156]          1</span></span>
<span><span class="co">##   Hispanic           1.0559 [0.72564, 1.5432]    0.78393</span></span>
<span><span class="co">##   Native_American     1.0978 [0.1249, 13.228]          1</span></span>
<span><span class="co">##   Other               1.1532 [0.7105, 1.8933]     0.5621</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Model performance:</span></span>
<span><span class="co">##                    Support  Accuracy Precision    Recall  F1 score</span></span>
<span><span class="co">##   Caucasian           2103 0.6585830 0.5773810 0.4720195 0.5194110</span></span>
<span><span class="co">##   African_American    3175 0.6724409 0.6652475 0.7525587 0.7062147</span></span>
<span><span class="co">##   Asian                 31 0.7419355 0.5000000 0.2500000 0.3333333</span></span>
<span><span class="co">##   Hispanic             509 0.6817289 0.5906040 0.4656085 0.5207101</span></span>
<span><span class="co">##   Native_American       11 0.6363636 0.6000000 0.6000000 0.6000000</span></span>
<span><span class="co">##   Other                343 0.6938776 0.6117647 0.4193548 0.4976077</span></span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="benchmarks">Benchmarks<a class="anchor" aria-label="anchor" href="#benchmarks"></a>
</h2>
<p>To ensure the accuracy of statistical results, <strong>jfa</strong>
employs automated <a href="https://github.com/koenderks/jfa/tree/development/tests/testthat" class="external-link">unit
tests</a> that regularly validate the output from the package against
the following established benchmarks in the area of algorithm
auditing:</p>
<ul>
<li>
<a href="https://cran.r-project.org/package=fairness" class="external-link">fairness</a>
(R package version 1.2.2)</li>
</ul>
</div>
<div class="section level2">
<h2 id="cheat-sheet">Cheat sheet<a class="anchor" aria-label="anchor" href="#cheat-sheet"></a>
</h2>
<p>The cheat sheet below will help you get started with
<strong>jfa</strong>’s algorithm audit functionality. A pdf version can
be downloaded <a href="https://github.com/koenderks/jfa/raw/development/man/figures/cheatsheet/cheatsheet-algorithm.pdf" class="external-link">here</a>.</p>
<p align="center">
<img src="cheatsheet-algorithm.png" alt="cheatsheet-algorithm" width="1000"></p>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0" line-spacing="2">
<div id="ref-friedler_2019" class="csl-entry">
Friedler, S. A., Scheidegger, C., Venkatasubramanian, S., Choudhary, S.,
Hamilton, E. P., &amp; Roth, D. (2019). A comparative study of
fairness-enhancing interventions in machine learning. <em>Proceedings of
the Conference on Fairness, Accountability, and Transparency</em>. <a href="https://doi.org/10.1145/3287560.3287589" class="external-link">https://doi.org/10.1145/3287560.3287589</a>
</div>
<div id="ref-kozodoi_2021" class="csl-entry">
Kozodoi, N., &amp; V. Varga, T. (2021). <em>Fairness: Algorithmic
fairness metrics</em>. <a href="https://CRAN.R-project.org/package=fairness" class="external-link">https://CRAN.R-project.org/package=fairness</a>
</div>
<div id="ref-pessach_2022" class="csl-entry">
Pessach, D., &amp; Shmueli, E. (2022). A review on fairness in machine
learning. <em>ACM Computing Surveys</em>, <em>55</em>(3), 1–44. <a href="https://doi.org/10.1145/3494672" class="external-link">https://doi.org/10.1145/3494672</a>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by <a href="https://koenderks.com" class="external-link">Koen Derks</a>.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
