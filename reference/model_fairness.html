<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Algorithm Auditing: Fairness Metrics and Bias Detection — model_fairness • jfa</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Algorithm Auditing: Fairness Metrics and Bias Detection — model_fairness"><meta property="og:description" content="This function detects bias in algorithmic decision-making
systems by computing various fairness metrics. It provides an assessment of
fairness across different groups based on the observed and predicted
outcomes. The function allows for evaluating fairness using metrics such as
demographic parity, proportional parity, predictive rate parity, accuracy
parity, false negative rate parity, false positive rate parity, true positive
rate parity, negative predicted value parity, and specificity parity and
decide whether groups are fair to a certain degree and within a certain
materiality threshold. Currently, it only supports binary classification."><meta property="og:image" content="https://koenderks.github.io/jfa/logo.png"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">jfa</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.7.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/jfa.html">Get started</a>
</li>
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/koenderks/jfa" class="external-link">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/koenderks/jfa/discussions" class="external-link">
    <span class="fa fa-users"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Algorithm Auditing: Fairness Metrics and Bias Detection</h1>
    <small class="dont-index">Source: <a href="https://github.com/koenderks/jfa/blob/HEAD/R/model_fairness.R" class="external-link"><code>R/model_fairness.R</code></a></small>
    <div class="hidden name"><code>model_fairness.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>This function detects bias in algorithmic decision-making
systems by computing various fairness metrics. It provides an assessment of
fairness across different groups based on the observed and predicted
outcomes. The function allows for evaluating fairness using metrics such as
demographic parity, proportional parity, predictive rate parity, accuracy
parity, false negative rate parity, false positive rate parity, true positive
rate parity, negative predicted value parity, and specificity parity and
decide whether groups are fair to a certain degree and within a certain
materiality threshold. Currently, it only supports binary classification.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">model_fairness</span><span class="op">(</span></span>
<span>  <span class="va">data</span>,</span>
<span>  <span class="va">sensitive</span>,</span>
<span>  <span class="va">target</span>,</span>
<span>  <span class="va">predictions</span>,</span>
<span>  reference <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  positive <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  materiality <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span>  alternative <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"two.sided"</span>, <span class="st">"greater"</span>, <span class="st">"less"</span><span class="op">)</span>,</span>
<span>  conf.level <span class="op">=</span> <span class="fl">0.95</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>
    <dl><dt>data</dt>
<dd><p>The input data.</p></dd>


<dt>sensitive</dt>
<dd><p>The column name indicating the sensitive variable.</p></dd>


<dt>target</dt>
<dd><p>The column name indicating the target class labels.</p></dd>


<dt>predictions</dt>
<dd><p>The column name indicating the predictions class labels.</p></dd>


<dt>reference</dt>
<dd><p>The reference class for computing the fairness metrics.
If <code>NULL</code> (the default), the first level of the <code>sensitive</code>
column is used.</p></dd>


<dt>positive</dt>
<dd><p>The positive class for computing the fairness metrics.
If <code>NULL</code> (the default), the first level of the <code>target</code>
column is used.</p></dd>


<dt>materiality</dt>
<dd><p>The materiality value for determining fairness.</p></dd>


<dt>alternative</dt>
<dd><p>The type of confidence interval to produce. Possible
options are <code>two.sided</code> (the default), <code>greater</code> and <code>less</code>.</p></dd>


<dt>conf.level</dt>
<dd><p>a numeric value between 0 and 1 specifying the
confidence level (i.e., 1 - audit risk / detection risk).</p></dd>

</dl></div>
    <div id="value">
    <h2>Value</h2>
    

<p>An object of class <code>jfaModelBias</code> containing:</p>
<dl><dt>reference</dt>
<dd><p>The reference group for computing the fairness metrics.</p></dd>

<dt>positive</dt>
<dd><p>The positive class used in computing the fairness metrics.</p></dd>

<dt>alternative</dt>
<dd><p>The type of confidence interval.</p></dd>

<dt>confusion.matrix</dt>
<dd><p>A list of confusion matrices for each group.</p></dd>

<dt>performance</dt>
<dd><p>A data frame containing performance metrics for each
  group, including accuracy, precision, recall, and F1 score.</p></dd>

<dt>fairness</dt>
<dd><p>A data frame containing fairness metrics for each group,
  including demographic parity, proportional parity, predictive rate parity,
  accuracy parity, false negative rate parity, false positive rate parity,
  true positive rate parity, negative predicted value parity, and statistical
  parity.</p></dd>

<dt>ratio</dt>
<dd><p>A data frame containing fairness ratios for each metric,
  comparing each group to the reference group.</p></dd>

<dt>materiality</dt>
<dd><p>The materiality value used to determine the out of bounds
  metrics.</p></dd>

<dt>data.name</dt>
<dd><p>The name of the input data object.</p></dd>

</dl></div>
    <div id="details">
    <h2>Details</h2>
    <p>The following fairness metrics are computed on the basis of the
  true positives (TP), false positives (FP), true negative (TN) and false
  negatives (FN) in the confusion matrix for each group.</p>
<ul><li><p>Demographic parity: measures whether the observed variable is
    distributed equally across different groups, calculated as TP + FP.</p></li>
<li><p>Proportional parity: measures whether the positive rate is
    distributed equally across different groups, calculated as (TP + FP) /
    (TP + FP + TN + FN).</p></li>
<li><p>Predictive rate parity: measures whether the positive prediction rate
    is the same across different groups, calculated as TP / (TP + FP).</p></li>
<li><p>Accuracy parity: measures whether the overall accuracy is the same
    across different groups, calculated as (TP + TN) / (TP + FP + TN + FN).</p></li>
<li><p>False negative rate parity: measures whether the false negative rate
    is the same across different groups, calculated as FN / (FP + FN).</p></li>
<li><p>False positive rate parity: measures whether the false positive rate
    is the same across different groups, calculated as FP / (TN + FP).</p></li>
<li><p>True positive rate parity: measures whether the true positive rate is
    the same across different groups, calculated as TP / (TP + FN).</p></li>
<li><p>Negative predicted value parity: measures whether the negative
    predicted value is the same across different groups, calculated as TN /
    (TN + FN).</p></li>
<li><p>Specificity parity: measures whether the true positive rate
    is the same across different groups, calculated as TN / (TN + FP).</p></li>
</ul></div>
    <div id="references">
    <h2>References</h2>
    <p>Pessach, D. &amp; Shmueli, E. (2022). A review on fairness in machine
  learning. <em>ACM Computing Surveys</em>, 55(3), 1-44. <a href="https://doi.org/10.1145/3494672" class="external-link">doi:10.1145/3494672</a></p>
    </div>
    <div id="author">
    <h2>Author</h2>
    <p>Koen Derks, <a href="mailto:k.derks@nyenrode.nl">k.derks@nyenrode.nl</a></p>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="fu">model_fairness</span><span class="op">(</span><span class="va">compas</span>, <span class="st">"Ethnicity"</span>, <span class="st">"TwoYrRecidivism"</span>, <span class="st">"Predicted"</span>,</span></span>
<span class="r-in"><span>  reference <span class="op">=</span> <span class="st">"Caucasian"</span>, positive <span class="op">=</span> <span class="st">"yes"</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> 	Fairness Metrics and Bias Detection</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> data:  compas</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> reference group:  Caucasian, positive class:  yes</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Sensitive groups (5):</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  African_American: 6 measures outside tolerance region</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Asian: 5 measures outside tolerance region</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Hispanic: 1 measures outside tolerance region</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Native_American: 5 measures outside tolerance region</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Other: 3 measures outside tolerance region</span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by <a href="https://koenderks.com" class="external-link">Koen Derks</a>.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer></div>

  


  

  </body></html>

